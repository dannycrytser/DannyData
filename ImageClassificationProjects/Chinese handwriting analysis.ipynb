{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This first chunk just imports some modules we will be using\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from subprocess import check_output\n",
    "##This sets addresses for the training and test datasets.\n",
    "## If you are running this on your own machine, you'll need to place the fashion-mnist_train and fashion-mnist_test\n",
    "## csv files into the same directory as this file and change the dirrectory path below.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to import the files into \n",
    "\n",
    "df = pd.read_csv('chinese_mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   suite_id  sample_id  code  value character\n",
      "0         1          1    10      9         九\n",
      "1         1         10    10      9         九\n",
      "2         1          2    10      9         九\n",
      "3         1          3    10      9         九\n",
      "4         1          4    10      9         九\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is just the labeling of the data -- the actual images are stored in another folder called 'Data.'\n",
    "\n",
    "The first (unlabeled) column is an id column. \n",
    "\n",
    "The second one labels the \"suite\" -- basically which person was drawing the characters. Each of the 100 volunteers created 10 samples, and each sample contains 15 characters (\"codes\"), so we should have 15000 rows. \n",
    "\n",
    "The last two columns contain the numerical value of the character (1-10, then the next 5 powers of 10) and the character itself. We will use the value column quite a bit as a label. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something a little annoying about the data frame: the \"finest\" part of the counter (code) is not moving the fastest. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "def reindex(suite_id, sample_id, code):\n",
    "    index = 150*(suite_id-1)+ 15*(sample_id-1) + code\n",
    "    return index-1\n",
    "    \n",
    "print(reindex(1,10,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['index'] = df.apply(lambda x: reindex(x.suite_id,x.sample_id,x.code),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    suite_id  sample_id  code  value character  index\n",
      "0          1          1    10      9         九      9\n",
      "1          1         10    10      9         九    144\n",
      "2          1          2    10      9         九     24\n",
      "3          1          3    10      9         九     39\n",
      "4          1          4    10      9         九     54\n",
      "5          1          5    10      9         九     69\n",
      "6          1          6    10      9         九     84\n",
      "7          1          7    10      9         九     99\n",
      "8          1          8    10      9         九    114\n",
      "9          1          9    10      9         九    129\n",
      "10        10          1    10      9         九   1359\n",
      "11        10         10    10      9         九   1494\n",
      "12        10          2    10      9         九   1374\n",
      "13        10          3    10      9         九   1389\n",
      "14        10          4    10      9         九   1404\n",
      "15        10          5    10      9         九   1419\n",
      "16        10          6    10      9         九   1434\n",
      "17        10          7    10      9         九   1449\n",
      "18        10          8    10      9         九   1464\n",
      "19        10          9    10      9         九   1479\n"
     ]
    }
   ],
   "source": [
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       suite_id  sample_id  code      value character  index\n",
      "6000          1          1     1          0         零      0\n",
      "7000          1          1     2          1         一      1\n",
      "8000          1          1     3          2         二      2\n",
      "9000          1          1     4          3         三      3\n",
      "10000         1          1     5          4         四      4\n",
      "11000         1          1     6          5         五      5\n",
      "12000         1          1     7          6         六      6\n",
      "13000         1          1     8          7         七      7\n",
      "14000         1          1     9          8         八      8\n",
      "0             1          1    10          9         九      9\n",
      "1000          1          1    11         10         十     10\n",
      "2000          1          1    12        100         百     11\n",
      "3000          1          1    13       1000         千     12\n",
      "4000          1          1    14      10000         万     13\n",
      "5000          1          1    15  100000000         亿     14\n",
      "6002          1          2     1          0         零     15\n",
      "7002          1          2     2          1         一     16\n",
      "8002          1          2     3          2         二     17\n",
      "9002          1          2     4          3         三     18\n",
      "10002         1          2     5          4         四     19\n"
     ]
    }
   ],
   "source": [
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       suite_id  sample_id  code  value character\n",
      "index                                            \n",
      "0             1          1     1      0         零\n",
      "1             1          1     2      1         一\n",
      "2             1          1     3      2         二\n",
      "3             1          1     4      3         三\n",
      "4             1          1     5      4         四\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing for us is the value of each row (we do not expect suite_id, sample_id, or code to have meaning for an image classification task, and character is redundant with value). Now we actually need the training features, and we have to get all the images wrangled into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i in range(1,101):\n",
    "    for j in range(1,11):\n",
    "        for k in range(1,16):\n",
    "            index  = reindex(i,j,k)\n",
    "            filename = '_'.join([str(i),str(j),str(k)])\n",
    "            filename = 'input_'+filename + '.jpg'\n",
    "            path = 'data/'+filename\n",
    "            img = mpimg.imread(path).flatten()\n",
    "            images += [img]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great, now we have a properly indexed dataframe. Let's check to make sure the actual images line up with the data. We pick a random entry from the character column, and note that the image does seem to match the character stored in the character column :). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "五\n"
     ]
    }
   ],
   "source": [
    "num = random.randrange(0,15000)\n",
    "\n",
    "print(df['character'][num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb7dc539460>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = df['image'][num]\n",
    "reshaped_image = np.reshape(image, (64, 64))\n",
    "plt.imshow(reshaped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the characters and the images line up correctly, we can discard those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       value                                              image\n",
      "index                                                          \n",
      "0          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "1          1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "2          2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3          3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "4          4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "5          5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "6          6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "7          7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "8          8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "9          9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns = ['suite_id','sample_id','code','character'])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a pretty useful form for the datframe: an index column, a label column ('value') and a feature column ('image'). We scale the image values so that they are all between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, numpy arrays don't allow string inputs, and we don't want a one hundred million-vector to represent fifteen possible values. So we will code the values as 100 = 11, 1000 = 12, 10000 = 13, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_changer(num):\n",
    "    if num > 10000:\n",
    "        num = 14\n",
    "    elif num > 1000:\n",
    "        num = 13\n",
    "    elif num > 100: \n",
    "        num = 12\n",
    "    elif num > 10:\n",
    "        num = 11\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['changed_value'] = df.apply(lambda x: number_changer(x.value), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['changed_value']\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for t in range(30):\n",
    "    print(labels[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We peel the values off the dataframe into a numpy array, the preferred input for fitting a keras model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split up the data into training and test sets. We could do this \"by hand\" if we wanted to, but it's nice to let sklearns's split package do the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands below cast the 15 possible labels in a one-to-hot encoding (example: if the label is 4, then it becomes a vector of length 15 with 0's everywhere except in the fourth position, where the value is 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_252 (Dense)            (None, 30)                122910    \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 123,845\n",
      "Trainable params: 123,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This specifies the size of the model for us \n",
    "#(it is still \"empty\" as it has not been compiled or trained)\n",
    "# Think of this as the blueprint for the model before it has been built\n",
    "# Each Dense layer is fully connected to the previous layer\n",
    "# The integer argument specifies the number of nodes\n",
    "# The activation is set to Rectified Linear Unit = (0.5)*(x+|x|)\n",
    "# Which is the standard activation for each node, \n",
    "# replacing the earlier standards of sigmoid and hyperbolic tangent.\n",
    "\n",
    "model  = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(30,activation=tf.nn.relu,input_shape=(4096,)))\n",
    "model.add(tf.keras.layers.Dense(20,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(15,activation=tf.nn.softmax))\n",
    "\n",
    "## Now we \"compile\" the model -- we actually build it!\n",
    "\n",
    "# We also specify a loss function (this is what the NN will try\n",
    "# to minimize during training), an optimizer (this is the \n",
    "# method by which the NN tries to minimize the loss),\n",
    "# and a metric (this is the metric by which we judge the performance\n",
    "# of the algorithm at its assigned task -- in this case classification)\n",
    "# The difference between loss and non-accuracy is a little subtle\n",
    "# Basically the job of the loss function is to be something that is \n",
    "# easy to calculate and optimize, and hopefully by minimizing loss\n",
    "# we get something that maximizes accuracy. \n",
    "\n",
    "# Think of this as putting in the wiring and plumbing and light fixtures\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "#note that the metrics argument is a list, because we can ask the \n",
    "#NN to calculate as many metrics as we like. We can only specify a single\n",
    "# loss function and optimizer though (although you could probably \n",
    "#stitch together several loss functions using a max or sum). \n",
    "\n",
    "model.summary()\n",
    "\n",
    "#after we print the model summary we see that there are 23550=785*30 \n",
    "# = 28*28*30 + 30\n",
    "#parameters for the first layer. Each of the 28*28*30 corresponds to \n",
    "# one pixel being added to one of the nodes in the first layer,\n",
    "#whereas the others are weights (I think) for the 30 nodes\n",
    "\n",
    "#Likewise we get 620 = 30*20 + 20 params for the second layer, the\n",
    "# 30*20 corresponding to the connections between nodes in the first \n",
    "#and second layers and the 20 corresponding to weights on the\n",
    "#second layer nodes themselves. And the pattern continues in the third \n",
    "#layer. IF we had chosen a non-Dense layer, then not every node \n",
    "#would connect to every node in the adjacent layers, and we \n",
    "#would have fewer parameters (probably there is some reason to try this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## This just specifies how often we feed the training data into the network (epochs is roughly the number \n",
    "## of iterations and batch is the amount of data fed each time). \n",
    "\n",
    "epochs_no = 10\n",
    "batch_no = 40\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below fits the neural network to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - 0s 986us/step - loss: 2.3229 - accuracy: 0.2540\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 0s 873us/step - loss: 1.7893 - accuracy: 0.4804\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 0s 917us/step - loss: 1.4827 - accuracy: 0.5644\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 0s 946us/step - loss: 1.2696 - accuracy: 0.6240\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 0s 961us/step - loss: 1.1145 - accuracy: 0.6654\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 0s 971us/step - loss: 0.9961 - accuracy: 0.7002\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 0s 891us/step - loss: 0.8985 - accuracy: 0.7270\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 0s 936us/step - loss: 0.8185 - accuracy: 0.7487\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 0s 888us/step - loss: 0.7464 - accuracy: 0.7688\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 0s 845us/step - loss: 0.6863 - accuracy: 0.7880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb79c7258e0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features,train_labels,epochs=epochs_no,batch_size=batch_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 515us/step - loss: 1.0544 - accuracy: 0.6667\n",
      "Test accuracy is  0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(test_features,test_labels)\n",
    "print(\"Test accuracy is \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the test accuracy is considerably worse than the training accuracy -- this indicates severe \n",
    "overfitting. Let's try to find the \"sweet spot\" where we minimize bias+variance. For now we'll just tinker with the number of epochs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1125/1125 [==============================] - 1s 704us/step - loss: 2.1354 - accuracy: 0.3403\n",
      "Epoch 2/7\n",
      "1125/1125 [==============================] - 1s 657us/step - loss: 1.4958 - accuracy: 0.5544\n",
      "Epoch 3/7\n",
      "1125/1125 [==============================] - 1s 651us/step - loss: 1.1785 - accuracy: 0.6396\n",
      "Epoch 4/7\n",
      "1125/1125 [==============================] - 1s 657us/step - loss: 0.9777 - accuracy: 0.7040\n",
      "Epoch 5/7\n",
      "1125/1125 [==============================] - 1s 658us/step - loss: 0.8399 - accuracy: 0.7435\n",
      "Epoch 6/7\n",
      "1125/1125 [==============================] - 1s 660us/step - loss: 0.7368 - accuracy: 0.7728\n",
      "Epoch 7/7\n",
      "1125/1125 [==============================] - 1s 657us/step - loss: 0.6569 - accuracy: 0.7935\n",
      "118/118 [==============================] - 0s 518us/step - loss: 0.9760 - accuracy: 0.7016\n",
      "Epoch 1/8\n",
      "1125/1125 [==============================] - 1s 695us/step - loss: 2.0954 - accuracy: 0.3480\n",
      "Epoch 2/8\n",
      "1125/1125 [==============================] - 1s 716us/step - loss: 1.5058 - accuracy: 0.5441\n",
      "Epoch 3/8\n",
      "1125/1125 [==============================] - 1s 705us/step - loss: 1.2106 - accuracy: 0.6288\n",
      "Epoch 4/8\n",
      "1125/1125 [==============================] - 1s 716us/step - loss: 1.0034 - accuracy: 0.6892\n",
      "Epoch 5/8\n",
      "1125/1125 [==============================] - 1s 713us/step - loss: 0.8636 - accuracy: 0.7319\n",
      "Epoch 6/8\n",
      "1125/1125 [==============================] - 1s 680us/step - loss: 0.7524 - accuracy: 0.7623\n",
      "Epoch 7/8\n",
      "1125/1125 [==============================] - 1s 665us/step - loss: 0.6665 - accuracy: 0.7880\n",
      "Epoch 8/8\n",
      "1125/1125 [==============================] - 1s 671us/step - loss: 0.5950 - accuracy: 0.8135\n",
      "118/118 [==============================] - 0s 532us/step - loss: 0.9401 - accuracy: 0.7099\n",
      "Epoch 1/9\n",
      "1125/1125 [==============================] - 1s 679us/step - loss: 2.0882 - accuracy: 0.3512\n",
      "Epoch 2/9\n",
      "1125/1125 [==============================] - 1s 672us/step - loss: 1.3651 - accuracy: 0.5755\n",
      "Epoch 3/9\n",
      "1125/1125 [==============================] - 1s 678us/step - loss: 1.0503 - accuracy: 0.6763\n",
      "Epoch 4/9\n",
      "1125/1125 [==============================] - 1s 679us/step - loss: 0.8697 - accuracy: 0.7318\n",
      "Epoch 5/9\n",
      "1125/1125 [==============================] - 1s 681us/step - loss: 0.7542 - accuracy: 0.7638\n",
      "Epoch 6/9\n",
      "1125/1125 [==============================] - 1s 715us/step - loss: 0.6765 - accuracy: 0.7871\n",
      "Epoch 7/9\n",
      "1125/1125 [==============================] - 1s 727us/step - loss: 0.6107 - accuracy: 0.8070\n",
      "Epoch 8/9\n",
      "1125/1125 [==============================] - 1s 753us/step - loss: 0.5591 - accuracy: 0.8207\n",
      "Epoch 9/9\n",
      "1125/1125 [==============================] - 1s 731us/step - loss: 0.5130 - accuracy: 0.8373\n",
      "118/118 [==============================] - 0s 538us/step - loss: 0.9857 - accuracy: 0.7123\n",
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2.0585 - accuracy: 0.3565\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 1s 980us/step - loss: 1.3669 - accuracy: 0.5798\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 1s 903us/step - loss: 1.0629 - accuracy: 0.6692\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 1s 881us/step - loss: 0.8862 - accuracy: 0.7186\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 1s 781us/step - loss: 0.7658 - accuracy: 0.7550\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 1s 784us/step - loss: 0.6775 - accuracy: 0.7828\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 1s 816us/step - loss: 0.6096 - accuracy: 0.8033\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 1s 826us/step - loss: 0.5522 - accuracy: 0.8234\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 1s 801us/step - loss: 0.5060 - accuracy: 0.8379\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 1s 767us/step - loss: 0.4669 - accuracy: 0.8479\n",
      "118/118 [==============================] - 0s 562us/step - loss: 0.9433 - accuracy: 0.7139\n",
      "Epoch 1/11\n",
      "1125/1125 [==============================] - 1s 887us/step - loss: 2.1513 - accuracy: 0.3284\n",
      "Epoch 2/11\n",
      "1125/1125 [==============================] - 1s 847us/step - loss: 1.4351 - accuracy: 0.5667\n",
      "Epoch 3/11\n",
      "1125/1125 [==============================] - 1s 706us/step - loss: 1.0731 - accuracy: 0.6736\n",
      "Epoch 4/11\n",
      "1125/1125 [==============================] - 1s 699us/step - loss: 0.8708 - accuracy: 0.7310\n",
      "Epoch 5/11\n",
      "1125/1125 [==============================] - 1s 742us/step - loss: 0.7398 - accuracy: 0.7671\n",
      "Epoch 6/11\n",
      "1125/1125 [==============================] - 1s 745us/step - loss: 0.6497 - accuracy: 0.7935\n",
      "Epoch 7/11\n",
      "1125/1125 [==============================] - 1s 737us/step - loss: 0.5835 - accuracy: 0.8149\n",
      "Epoch 8/11\n",
      "1125/1125 [==============================] - 1s 757us/step - loss: 0.5280 - accuracy: 0.8323\n",
      "Epoch 9/11\n",
      "1125/1125 [==============================] - 1s 777us/step - loss: 0.4813 - accuracy: 0.8476\n",
      "Epoch 10/11\n",
      "1125/1125 [==============================] - 1s 795us/step - loss: 0.4421 - accuracy: 0.8599\n",
      "Epoch 11/11\n",
      "1125/1125 [==============================] - 1s 840us/step - loss: 0.4115 - accuracy: 0.8712\n",
      "118/118 [==============================] - 0s 526us/step - loss: 0.9714 - accuracy: 0.7237\n",
      "Epoch 1/12\n",
      "1125/1125 [==============================] - 1s 711us/step - loss: 2.1090 - accuracy: 0.3503\n",
      "Epoch 2/12\n",
      "1125/1125 [==============================] - 1s 748us/step - loss: 1.4247 - accuracy: 0.5666\n",
      "Epoch 3/12\n",
      "1125/1125 [==============================] - 1s 705us/step - loss: 1.0833 - accuracy: 0.6685\n",
      "Epoch 4/12\n",
      "1125/1125 [==============================] - 1s 732us/step - loss: 0.8917 - accuracy: 0.7270\n",
      "Epoch 5/12\n",
      "1125/1125 [==============================] - 1s 722us/step - loss: 0.7701 - accuracy: 0.7604\n",
      "Epoch 6/12\n",
      "1125/1125 [==============================] - 1s 745us/step - loss: 0.6779 - accuracy: 0.7843\n",
      "Epoch 7/12\n",
      "1125/1125 [==============================] - 1s 735us/step - loss: 0.6109 - accuracy: 0.8072\n",
      "Epoch 8/12\n",
      "1125/1125 [==============================] - 1s 767us/step - loss: 0.5488 - accuracy: 0.8271\n",
      "Epoch 9/12\n",
      "1125/1125 [==============================] - 1s 789us/step - loss: 0.5045 - accuracy: 0.8424\n",
      "Epoch 10/12\n",
      "1125/1125 [==============================] - 1s 740us/step - loss: 0.4588 - accuracy: 0.8558\n",
      "Epoch 11/12\n",
      "1125/1125 [==============================] - 1s 707us/step - loss: 0.4215 - accuracy: 0.8693\n",
      "Epoch 12/12\n",
      "1125/1125 [==============================] - 1s 714us/step - loss: 0.3933 - accuracy: 0.8767\n",
      "118/118 [==============================] - 0s 507us/step - loss: 1.0300 - accuracy: 0.7184\n"
     ]
    }
   ],
   "source": [
    "epoch_values = [t+1 for t in range(6,12)]\n",
    "\n",
    "test_accuracy = []\n",
    "\n",
    "for num in epoch_values:\n",
    "    epochs_no = num\n",
    "    model  = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(30,activation=tf.nn.relu,input_shape=(4096,)))\n",
    "    model.add(tf.keras.layers.Dense(20,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(15,activation=tf.nn.softmax))\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics = ['accuracy'])\n",
    "    batch_no = 10\n",
    "    model.fit(train_features,train_labels,epochs=epochs_no,batch_size=batch_no)\n",
    "    test_loss,test_acc = model.evaluate(test_features,test_labels)\n",
    "    test_accuracy.append([test_loss,test_acc])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb7e148f2e0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = [y for [x,y] in test_accuracy]\n",
    "plt.plot(epoch_values,accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the best performance is somewhere around 11 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [epoch_values, accuracies]\n",
    "\n",
    "test_df = pd.DataFrame(list(zip(epoch_values, accuracies)), \n",
    "               columns =['Epochs', 'Accuracy']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
