{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "## First we will read the .csv file of tweets into a pandas dataframe. \n",
    "## Note that this \n",
    "\n",
    "tweets = pd.read_csv('covid19_tweets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## If you comment out the commands below, you can see the format of the dataframe. \n",
    "\n",
    "## The first column is an index, then you have user_name, user_location, user_description,\n",
    "## user_created, user_followers, user_friends, user_favourites, user_verified (True/False),\n",
    "## date, text, hashtags (presented as a list of strings), \n",
    "## source (Twitter Web App, for android, etc), and is_retweet (True/False)\n",
    "\n",
    "\n",
    "\n",
    "##print(len(tweets))\n",
    "##print(tweets.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is an example of the sort of simple string commands we will use to \n",
    "## determine likely political leaning. Uncomment the line below to see if the \n",
    "## author of the first tweet in the dataframe has the word conservative in their \n",
    "## user description. \n",
    "\n",
    "##'conservative' in tweets.loc[0]['user_description'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our first goal is to extract a subset of the tweet texts, labeled according to political\n",
    "## leaning. It's hard to extract someone's political stance just from the information\n",
    "## available in this table, but we will make a guess that a user_description that\n",
    "## uses a lot of right-wing adjectives (conservative, traditional, etc.) is probably\n",
    "## conservative and a user_description that uses a lot of left-wing adjectives (liberal,\n",
    "## progressive, etc.) is probably liberal. Of course, many people leave their descriptions blank\n",
    "## or don't include such terms; we will simply omit their posts. \n",
    "\n",
    "## The first thing we do is define a function that will extract the political leaning\n",
    "## of a tweet's author. We build it out of somewhat simpler functions: \n",
    "## first a function that checks if a word is in a user_description, then a function\n",
    "## that checks if any of a list of words appears in a user_description,\n",
    "## and finally a function that checks to see if \n",
    "\n",
    "def word_in_desc(word,desc):\n",
    "    return word in str(desc)\n",
    "\n",
    "def some_word_in_desc(lst,desc):\n",
    "    state = False\n",
    "    for word in lst:\n",
    "        if word_in_desc(word,desc):\n",
    "            state = True\n",
    "            break\n",
    "    return state\n",
    "\n",
    "def political_leaning(desc, \n",
    "                      liberal_words=['feminist','ImWithHer','liberal','progressive','democratic','democrat','leftist'],\n",
    "                      conservative_words=['MAGA','patriot','conservative','traditional','libertarian','republican']):\n",
    "    if some_word_in_desc(liberal_words,desc) and not some_word_in_desc(conservative_words,desc):\n",
    "        return \"L\"\n",
    "    elif some_word_in_desc(conservative_words,desc) and not some_word_in_desc(liberal_words,desc):\n",
    "        return \"R\"\n",
    "    else:\n",
    "        return \"I\"\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166656\n",
      "1080\n",
      "1499\n",
      "2579\n"
     ]
    }
   ],
   "source": [
    "## We should check that this works at least somewhat reasonably. \n",
    "\n",
    "tweets['political_leaning']=tweets.user_description.apply(lambda x: political_leaning(x))\n",
    "\n",
    "print(len(tweets))\n",
    "liberal_tweets = tweets[tweets.political_leaning == 'L']\n",
    "print(len(liberal_tweets))\n",
    "conservative_tweets = tweets[tweets.political_leaning == 'R']\n",
    "print(len(conservative_tweets))\n",
    "partisan_tweets = tweets[tweets.political_leaning != 'I']\n",
    "print(len(partisan_tweets))\n",
    "## Somewhat unfortunately we have a pretty small set of tweets to work with after \n",
    "## filtering down to the partisan tweets. Also the conservative tweets outnumber the \n",
    "## liberal tweets. However it seems like we should be able to find _some_ interesting\n",
    "## patterns even with just a couple thousand tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to decide if political leaning has an effect on sentiment. We need to build a \n",
    "classifier. We will use the NLTK module, which is a popular tool for analyzing \n",
    "\"natural language\" documents such as tweets. ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "\n",
    "## First we are going to use some standard training tweets to create a model. \n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "\n",
    "tknz = TweetTokenizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tweet_text_tokenizes = [tknz.tokenize(tweet) for tweet in tweet_texts]\n",
    "## print(tweet_text_tokenizes[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to process the words. The first step is Lemmatization: reducing a word to its root or canonical form.\n",
    "\n",
    "\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "## If you are missing the two modules, uncomment the code. \n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# The following function uses the pos_tag information to feed the lemmatizer (which can only operate when it \n",
    "## knows what part of speech the input word is)\n",
    "# def lemmatize_sentence(tokens):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     lemmatized_sentence = []\n",
    "#     for word, tag in pos_tag(tokens):\n",
    "#         if tag.startswith('NN'):\n",
    "#             pos = 'n'\n",
    "#         elif tag.startswith('VB'):\n",
    "#             pos = 'v'\n",
    "#         else:\n",
    "#             pos = 'a'\n",
    "#         lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "#     return lemmatized_sentence\n",
    "\n",
    "# print(lemmatize_sentence(tweet_tokens[200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOW we need to clean up the lemmatized posts. \n",
    "\n",
    "## We do this via a function called remove_noise that begins by removing URLS (identified as a regular expression),\n",
    "## and twitter handles (identified with a @ symbol). \n",
    "\n",
    "## We incorporate the lemmatization from the previous thing into this function. Note that we also have a \n",
    "## thing that filters out punctuation, as well as the so-called stop words,\n",
    "##  which are in the typle of stop_words provided as the second argument)\n",
    "\n",
    "import re, string\n",
    "\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you haven't got the NLTK module stopwords, you can uncomment the following line of code to get it. \n",
    "\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dang', 'that', 'is', 'some', 'rad', '@AbzuGame', '#fanart', '!', ':D', 'https://t.co/bI8k8tb9ht']\n",
      "['dang', 'rad', '#fanart', ':d']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "positive_tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "negative_tweet_tokens = twitter_samples.tokenized('negative_tweets.json')\n",
    "\n",
    "positive_cleaned_tokens_list = []\n",
    "negative_cleaned_tokens_list = []\n",
    "\n",
    "for tokens in positive_tweet_tokens:\n",
    "    positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "for tokens in negative_tweet_tokens:\n",
    "    negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "    \n",
    "covid_cleaned_tokens_list = []\n",
    "\n",
    "    \n",
    "## Here is an example of what remove noise does: the first list is the list of tokens in the 500th\n",
    "## positive tweet, the second is what happens to that list after we delete all the 'junk'\n",
    "\n",
    "\n",
    "print(positive_tweet_tokens[500])\n",
    "print(positive_cleaned_tokens_list[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We are going to use Na√Øve Bayes for our classification. The NB classifier in NLTK requires the \n",
    "## tweets to be converted to dictionary format, with the words as keys and True for each value.\n",
    "\n",
    "\n",
    "\n",
    "def get_tweets_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tweet_tokens)\n",
    "\n",
    "positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n",
    "negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n",
    "## Now lets label the training tweets as either Positive or Negative\n",
    "import random\n",
    "## we import the random module because we will randomly shuffle the dataset, \n",
    "## after it's been labeled, into a training chunk and a testing chunk\n",
    "\n",
    "positive_dataset = [(tweet_dict,\"Positive\")\n",
    "                   for tweet_dict in positive_tokens_for_model]\n",
    "negative_dataset = [(tweet_dict,\"Negative\")\n",
    "                   for tweet_dict in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train_data = dataset[:7000]\n",
    "test_data = dataset[7000:]\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "# print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
    "\n",
    "# print(classifier.show_most_informative_features(20))\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def string_to_classification_verbose(string):\n",
    "    tokens = remove_noise(word_tokenize(string))\n",
    "    print('The classification is: ',classifier.classify(dict([token,True] for token in tokens)))\n",
    "    probs = classifier.prob_classify(dict([token,True] for token in tokens))\n",
    "    print('Negative probability ',probs.prob('Negative'))\n",
    "    print('Positive probability ',probs.prob('Positive'))\n",
    "    \n",
    "def string_to_classification_terse(string):\n",
    "    tokens = remove_noise(word_tokenize(string))\n",
    "    return classifier.classify(dict([token,True] for token in tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification is:  Negative\n",
      "Negative probability  0.8662386457283909\n",
      "Positive probability  0.1337613542716073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Uncomment the line below to see how the string_to_classification_verbose function works\n",
    "\n",
    "string_to_classification_verbose('people aren‚Äôt aware of this but HW assassinated 25 percent of Americans after the convention and that explains this shift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(string_to_classification_terse('people aren‚Äôt aware of this but HW assassinated 25 percent of Americans after the convention and that explains this shift'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-43c178619508>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partisan_tweets['sentiment'] = partisan_tweets.text.apply(lambda x: string_to_classification_terse(x))\n"
     ]
    }
   ],
   "source": [
    "## Now we can define our dataset \n",
    "\n",
    "partisan_tweets['sentiment'] = partisan_tweets.text.apply(lambda x: string_to_classification_terse(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         user_name          user_location  \\\n",
      "66                                         Matty A       New York, NY USA   \n",
      "164                                    ‚ùå Romulus ‚ùå                      ‚ùå   \n",
      "178                                  BellaLunaTick  Occupied Shawnee Land   \n",
      "257                             John Lichtenberger            Roxbury, NJ   \n",
      "272                                       Jimbo360           Florida, USA   \n",
      "310                             John Lichtenberger            Roxbury, NJ   \n",
      "389                       The Soulsborne Waifu ‚öîÔ∏èüåô                    NaN   \n",
      "476  TinkerLane üò∑ Mask/Handwashing/Distance ‚öΩüóΩüååüç∑üêãüåä          Virginia, USA   \n",
      "481                               Samia Ali Salama      Pennsylvania, USA   \n",
      "549                                      Ben Foerg            Los Angeles   \n",
      "\n",
      "                                      user_description         user_created  \\\n",
      "66   üá∫üá∏  Happily Married & a Proud Son of a U.S Nav...  2014-02-01 21:44:37   \n",
      "164  #MAGA Hardworking American living in U.S. wher...  2013-01-30 09:14:18   \n",
      "178  Heart of Virginny-No Gadsden flag, coal-rollin...  2014-06-19 22:47:31   \n",
      "257  #Christian | #lawyer (Ret.) Tweets on Christia...  2009-04-05 22:31:06   \n",
      "272  Floridian here proudly supporting @realDonaldT...  2019-05-03 13:07:46   \n",
      "310  #Christian | #lawyer (Ret.) Tweets on Christia...  2009-04-05 22:31:06   \n",
      "389  Just a bitch who knows how to do makeup and ki...  2018-04-18 02:50:01   \n",
      "476  Luv travel w. wife; lib male; #MFImpeached #Re...  2009-02-23 21:32:38   \n",
      "481  Mother #veteran #liberal #atheist #poet, #LGBT...  2009-10-27 13:30:12   \n",
      "549  songwriter, multi-instrumentalist / amateur po...  2014-07-29 21:52:20   \n",
      "\n",
      "     user_followers  user_friends  user_favourites  user_verified  \\\n",
      "66             3924          4487            93575          False   \n",
      "164            3330          4980            25355          False   \n",
      "178            3133          3115            34146          False   \n",
      "257           38301         38729            27463          False   \n",
      "272              56           422             1677          False   \n",
      "310           38301         38729            27463          False   \n",
      "389              73           245             5193          False   \n",
      "476            4809          4920             2021          False   \n",
      "481            3134          2794            90437          False   \n",
      "549             235           241             5981          False   \n",
      "\n",
      "                    date                                               text  \\\n",
      "66   2020-07-25 12:25:20  See this Instagram post by @facts.covid19 http...   \n",
      "164  2020-07-25 12:22:15  @JoeBiden What fight is the creepy and delusio...   \n",
      "178  2020-07-25 12:21:35  @GovernorGreg‚Äôs actions killed.  Are still kil...   \n",
      "257  2020-07-25 12:19:09  Pandemic could push more N. Carolina families ...   \n",
      "272  2020-07-25 12:18:36  Sad Reality: Hundreds of Cars line up drive th...   \n",
      "310  2020-07-25 12:17:29  This WILL be the new way of life-until Nov. 4,...   \n",
      "389  2020-07-25 12:14:45  Voting for Trump. He isn‚Äôt backtracking on his...   \n",
      "476  2020-07-25 12:11:44  The #OrangeBaboon wants to make sure we have o...   \n",
      "481  2020-07-25 12:11:34  @forwardarc @realDonaldTrump @VP If the U.S. d...   \n",
      "549  2020-07-25 12:09:17  You don‚Äôt see a lot of articles about granny o...   \n",
      "\n",
      "                                              hashtags              source  \\\n",
      "66                                                 NaN     Twitter Web App   \n",
      "164                                                NaN     Twitter Web App   \n",
      "178                                                NaN     Twitter Web App   \n",
      "257  ['homeschooling', 'COVID19', 'coronavirus', 'NC']     Twitter Web App   \n",
      "272                                        ['COVID19']     Twitter Web App   \n",
      "310                                                NaN     Twitter Web App   \n",
      "389                                        ['COVID19']  Twitter for iPhone   \n",
      "476                        ['OrangeBaboon', 'COVID19']     Twitter Web App   \n",
      "481                                                NaN  Twitter for iPhone   \n",
      "549                                        ['COVID19']  Twitter for iPhone   \n",
      "\n",
      "     is_retweet political_leaning sentiment  \n",
      "66        False                 R  Positive  \n",
      "164       False                 R  Negative  \n",
      "178       False                 R  Negative  \n",
      "257       False                 R  Negative  \n",
      "272       False                 R  Negative  \n",
      "310       False                 R  Positive  \n",
      "389       False                 R  Negative  \n",
      "476       False                 R  Negative  \n",
      "481       False                 L  Negative  \n",
      "549       False                 R  Positive  \n"
     ]
    }
   ],
   "source": [
    "## Lets see what we have: basically its the original partisan tweets dataset (including L/R labels)\n",
    "## but augmented with a sentiment column)\n",
    "\n",
    "\n",
    "\n",
    "print(partisan_tweets.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    political_leaning sentiment\n",
      "66                  R  Positive\n",
      "164                 R  Negative\n",
      "178                 R  Negative\n",
      "257                 R  Negative\n",
      "272                 R  Negative\n",
      "310                 R  Positive\n",
      "389                 R  Negative\n",
      "476                 R  Negative\n",
      "481                 L  Negative\n",
      "549                 R  Positive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political_leaning</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>553</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>762</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment          Negative  Positive\n",
       "political_leaning                    \n",
       "L                       553       527\n",
       "R                       762       737"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets cut our dataset down to \n",
    "\n",
    "df = partisan_tweets.filter(items = ['political_leaning','sentiment'])\n",
    "print(df.head(10))\n",
    "\n",
    "pd.crosstab(df.political_leaning,df.sentiment)\n",
    "\n",
    "## Now we can do some statistics: the negativity ratio for liberal tweets is 544/536 ~ 1.02. \n",
    "## The negativity ratio for conservative tweets is 768/731 = 1.05. So the proportions are not\n",
    "## much different. Possibly if we changed our classifier (there is a more rich array of bayesian\n",
    "## classifiers available in the Scikit package) or if we expanded our partisan dictionaries, \n",
    "## we would find a difference. \n",
    "\n",
    "## It is somewhat noteworthy that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The total number of positive tweets is 536+731 = 1267, whereas there are 1312 negative tweets. \n",
    "## The pooled estimate of the proportion of negative tweets is 1312/(1312+1267) = 0.50872. \n",
    "\n",
    "## The standard error when we get is sqrt(.25(1/1080) + .25(1/1499)) = 0.01995643588\n",
    "\n",
    "## The proportion of liberal tweets that are negative is 0.5037037037\n",
    "\n",
    "## The proportion of conservative tweets that are negative is 0.51234156104\n",
    "\n",
    "## The difference of the proportions is only 0.43 times the standard error - falls under the 1.96*SE threshold\n",
    "## for significance! So we observe a difference in the (small) data set we filtered down to, but it is not a \n",
    "## statistically significant one. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
